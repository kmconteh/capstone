{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "#### 1. Data Cleaning\n",
    "#### 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./datasets/all indicators.csv does not exist: './datasets/all indicators.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4c2502a1b16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/all indicators.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./datasets/all indicators.csv does not exist: './datasets/all indicators.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/all indicators.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking total number of null's\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming null's per column\n",
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Country Name').isnull().sum(axis=1).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/all indicators_final.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking total number of NaN's\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of nulls by column\n",
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing indicators due to recentness of country inputs \n",
    "#or where there is less than 100 country inputs for the indicator\n",
    "df.drop(['IQ_CPA_ECON_XQ_2018', 'IQ_CPA_SOCI_XQ_2018', \n",
    "         'IQ_CPA_PUBS_XQ_2018', 'SH.MED.BEDS.ZS_2015',\n",
    "         'SI.POV.GAPS_2018', 'SI.POV.DDAY_2018', 'IS.RRS.TOTL.KM_2018',\n",
    "         'pop_safe_man_san_tot%_2017', 'pop_safe_man_san_urb%_2017',\n",
    "         'pop_safe_man_san_rur%_2017', 'chw_#', 'med_path_lab_sci#',\n",
    "         'med_path_lab_tech#', 'gen_med_prac#', 'spec_med_prac#',\n",
    "         'is_air_dprt_2018', 'NY.GNS.ICTR.ZS_2018', 'med_doc#',\n",
    "         'ST.INT.RCPT.XP.ZS_2018', 'ST.INT.XPND.MP.ZS_2018', \n",
    "         'pop_basic_san_rur%_2017', 'pop_basic_san_urb%_2017', \n",
    "         'skl_health_pro_per10k#', 'BX.TRF.PWKR.CD.DT_2018'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming removal of columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing indicators already used for the INFORM risk score (target y-variable) \n",
    "#to ensure independence of variables for predictive modeling\n",
    "df.drop(['EN.POP.DNST_2018', 'EN.POP.SLUM.UR.ZS_2014', \n",
    "         'SP.URB.TOTL.IN.ZS_2018', 'pop_bas_hnd_wash_fac%_tot_2017', \n",
    "         'pop_bas_hnd_wash_fac%_urb_2017', 'pop_bas_hnd_wash_fac%_rur_2017', \n",
    "         'Urban population growth (annual %)','Population living in urban areas (%)', \n",
    "         'Proportion of population with basic handwashing facilities on premises (% of population)', \n",
    "         'Population living in slums (% of urban population)', \n",
    "         'Children under 5 (% of population)', 'GCRI Violent Conflict probability', \n",
    "         'GCRI Highly Violent Conflict probability', 'Gender Inequality Index.1', 'Human Development Index', \n",
    "         'Multidimensional Poverty Index', 'Humanitarian Aid (FTS)', 'Development Aid (ODA)', 'Net ODA received (% of GNI)', \n",
    "         'Volume of remittances (in USD) as a proportion of total GDP (%)','Mortality rate, under-5', 'Incidence of Tuberculosis', \n",
    "         'Estimated number of people living with HIV - Adult (>15) rate', 'Number of new HIV infections per 1,000 uninfected population', \n",
    "         'Malaria incidence per 1,000 population at risk', 'Number of people requiring interventions against neglected tropical diseases', \n",
    "         'Gender Inequality Index', 'Income Gini coefficient', 'People affected by Natural Disasters', 'People affected by Natural Disasters', \n",
    "         'People affected by Natural Disasters', 'Internally displaced persons (IDPs)', \n",
    "         'Refugees and asylum-seekers by country of asylum', 'Returned Refugees', \n",
    "         'Average Dietary Energy Supply Adequacy','Prevalence of Undernourishment', 'Government Effectiveness', \n",
    "         'Corruption Perception Index', 'Access to electricity', 'Adult literacy rate', \n",
    "         'Individuals using the Internet', 'Mobile cellular subscriptions', \n",
    "         'People using at least basic sanitation services (% of population)', \n",
    "         'People using at least basic drinking water services (% of population)', \n",
    "         'Physicians Density', 'Current health expenditure per capita', \n",
    "         'GDP per capita (current US$)', 'Total Population', \n",
    "         'Air transport, passengers carried', \n",
    "         'International tourism, number of arrivals', \n",
    "         'IHR capacity score: Points of entry', 'Access to Cities', \n",
    "         'Public trust in politicians', '1+ underlying conditions plus 0 conditions (65+ yrs)', \n",
    "         'Gender Inequality Index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming removal of columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming removal of all nulls\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns for ease of reference\n",
    "df = df.rename(columns={\"IncomeGroup\": \"Income Group\", \n",
    "                   \"HAZARD & EXPOSURE\": \"INFORM: Hazard & Exposure risk score\",\n",
    "                   \"VULNERABILITY\": \"INFORM: Vulnerability risk score\", \n",
    "                   \"LACK OF COPING CAPACITY\": \"INFORM: Lack of Coping Capacity risk score\",\n",
    "                   \"EPIDEMIC INFORM RISK\": \"INFORM: Epidemic risk score\",\n",
    "                   \"EPIDEMIC RISK CLASS\": \"INFORM: Epidemic risk class\",\n",
    "                   \"doc_#\": \"Medical doctors (#)\", \n",
    "                   \"doc_per10k#\": \"Medical doctors (# per 10,000)\",\n",
    "                   \"EN.URB.LCTY.UR.ZS_2018\": \"Urban population (%)\", \n",
    "                   \"gov_health_exp%\": \"Government health expenditure (%)\",\n",
    "                   \"hos.beds.per10k.#\": \"Hospital bed density (#)\", \n",
    "                   \"IT.CEL.SETS.P2_2018\": \"Mobile subscriptions (# per 100 people)\",\n",
    "                   \"IT.MLT.MAIN.P2_2018\": \"Fixed telephone subscriptions (# per 100 people)\", \n",
    "                   \"IT.NET.BBND.P2_2018\": \"Fixed broadband subscriptions (# per 100 people)\",\n",
    "                   \"nur_mid_wife_per10k#\": \"Nursing and midwife personnel (# per 10,000)\", \n",
    "                   \"nurse#\": \"Nurses (#)\",\n",
    "                   \"NY.GDP.MKTP.KD.ZG_2018\": \"GDP growth (annual %)\", \n",
    "                   \"NY.GDP.PCAP.CD_2018\": \"GDP per capita (current US$)\",\n",
    "                   \"NY.GDP.PCAP.KD.ZG_2018\": \"GDP per capita growth (annual %)\", \n",
    "                   \"NY.GNP.MKTP.PP.CD_2018\": \"GNI, PPP (current international $)\",\n",
    "                   \"NY.GNP.PCAP.PP.CD_2018\": \"GNI per capita, PPP (current international $)\", \n",
    "                   \"pop_basic_san_tot%_2017\": \"Handwashing with soap (%)\",\n",
    "                   \"SH_DTH_COMM_ZS_2016\": \"Death by communicable diseases (% of total)\", \n",
    "                   \"SH_STA_DIAB_ZS_2019\": \"Diabetes prevalence (% of population ages 20 to 79)\",\n",
    "                   \"SL_AGR_EMPL_FE_ZS_2019\": \"Employment in agriculture, female (%)\", \n",
    "                   \"SL_AGR_EMPL_MA_ZS_2019\": \"Employment in agriculture, male (%)\",\n",
    "                   \"SL_EMP_VULN_ZS_2019\": \"Employment in industry, female (%)\", \n",
    "                   \"SL_IND_EMPL_MA_ZS_2019\": \"Employment in industry, male (%)\",\n",
    "                   \"SL_SRV_EMPL_FE_ZS_2019\": \"Employment in services, female (%)\", \n",
    "                   \"SL.EMP.WORK.FE.ZS_2019\": \"Wage and salaried workers, female (%)\",\n",
    "                   \"SL.EMP.WORK.MA.ZS_2019\": \"Wage and salaried workers, male (%)\", \n",
    "                   \"SL.SRV.EMPL.MA.ZS_2019\": \"Employment in services, male (%)\",\n",
    "                   \"SL.TLF.TOTL.IN_2019\": \"Labor force, total (#)\", \n",
    "                   \"SM.POP.NETM_2017\": \"Net migration (#)\",\n",
    "                   \"SM.POP.REFG_2018\": \"Refugee population by country of asylum (#)\", \n",
    "                   \"SP.POP.0014.TO.ZS_2018\": \"Population ages 0-14 (% of total population)\",\n",
    "                   \"SP.POP.1564.TO.ZS_2018\": \"Population ages 15-64 (% of total population)\", \n",
    "                   \"SP.POP.65UP.TO.ZS_2018\": \"Population ages 65 and above (% of total population)\",\n",
    "                   \"SP.POP.TOTL_2018\": \"Population, total (#)\", \n",
    "                   \"C.1.1\": \"Policies to implement IHR (score out of 100)\",\n",
    "                   \"C.1.2\": \"Financing to implement IHR (score out of 100)\", \n",
    "                   \"C.1.3\": \"Financing to respond to health emergencies (score out of 100)\",\n",
    "                   \"C.10.1\": \"Risk communication capacity (score out of 100)\", \n",
    "                   \"C.11.1\": \"Transportation capacity (score out of 100)\",\n",
    "                   \"C.11.2\": \"Health response at points of entry (score out of 100)\", \n",
    "                   \"C.12.1\": \"Detection resources and alert (score out of 100)\",\n",
    "                   \"C.2.2\": \"IHR coordination (score out of 100)\", \n",
    "                   \"C.5.3\": \"Lab testing access (score out of 100)\",\n",
    "                   \"C.6.1\": \"Early warning surveillance (score out of 100)\", \n",
    "                   \"C.6.2\": \"Mechanism for event management (score out of 100)\",\n",
    "                   \"C.7.1\": \"Human Resources to implement IHR (score out of 100)\", \n",
    "                   \"C.8.1\": \"Emergency preparedness planning (score out of 100)\",\n",
    "                   \"C.8.2\": \"Management of health emergency response (score out of 100)\", \n",
    "                   \"C.8.3\": \"Emergency resource mobilization (score out of 100)\",\n",
    "                   \"C.9.1\": \"IHR case management (score out of 100)\", \n",
    "                   \"C.9.2\": \"Infection prevention and control (score out of 100)\",\n",
    "                   \"C.9.3\": \"Access to essential health services (score out of 100)\"\n",
    "                  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the following columns were created for further data exploration:\n",
    "- Regional average score of risk to an epidemic\n",
    "- Regional average risk score for each epidemic sub-category (Hazard & Exposure, Vulnerability, Lack of Coping Capacity)\n",
    "- Average epidemic risk score by income group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataframe for each region and calculate average INFORM risk scores by region\n",
    "df_eur= df[df[\"Region\"] == 'Europe & Central Asia']\n",
    "print('Europe & Central Asia INFORM: Hazard & Exposure risk score average: ', df_eur['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('Europe & Central Asia INFORM: Vulnerability risk score average: ', df_eur['INFORM: Vulnerability risk score'].mean())\n",
    "print('Europe & Central Asia INFORM: Lack of Coping Capacity risk score average: ', df_eur['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('Europe & Central Asia INFORM risk score average: ', df_eur['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_afr= df[df[\"Region\"] == 'Sub-Saharan Africa']\n",
    "print('Sub-Saharan Africa INFORM: Hazard & Exposure risk score average: ', df_afr['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('Sub-Saharan Africa INFORM: Vulnerability risk score average: ', df_afr['INFORM: Vulnerability risk score'].mean())\n",
    "print('Sub-Saharan Africa INFORM: Lack of Coping Capacity risk score average: ', df_afr['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('Sub-Saharan Africa INFORM risk score average: ', df_afr['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_lat= df[df[\"Region\"] == 'Latin America & Caribbean']\n",
    "print('Latin America & Caribbean INFORM: Hazard & Exposure risk score average: ', df_lat['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('Latin America & Caribbean INFORM: Vulnerability risk score average: ', df_lat['INFORM: Vulnerability risk score'].mean())\n",
    "print('Latin America & Caribbean INFORM: Lack of Coping Capacity risk score average: ', df_lat['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('Latin America & Caribbean INFORM risk score average: ', df_lat['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_asia= df[df[\"Region\"] == 'East Asia & Pacific']\n",
    "print('East Asia & Pacific INFORM: Hazard & Exposure risk score average: ', df_asia['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('East Asia & Pacific INFORM: Vulnerability risk score average: ', df_asia['INFORM: Vulnerability risk score'].mean())\n",
    "print('East Asia & Pacific INFORM: Lack of Coping Capacity risk score average: ', df_asia['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('East Asia & Pacific INFORM risk score average: ', df_asia['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_mena= df[df[\"Region\"] == 'Middle East & North Africa']\n",
    "print('Middle East & North Africa INFORM: Hazard & Exposure risk score average: ', df_mena['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('Middle East & North Africa INFORM: Vulnerability risk score average: ', df_mena['INFORM: Vulnerability risk score'].mean())\n",
    "print('Middle East & North Africa INFORM: Lack of Coping Capacity risk score average: ', df_mena['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('Middle East & North Africa INFORM risk score average: ', df_mena['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_soasia= df[df[\"Region\"] == 'South Asia']\n",
    "print('South Asia INFORM: Hazard & Exposure risk score average: ', df_soasia['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('South Asia INFORM: Vulnerability risk score average: ', df_soasia['INFORM: Vulnerability risk score'].mean())\n",
    "print('South Asia INFORM: Lack of Coping Capacity risk score average: ', df_soasia['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('South Asia INFORM risk score average: ', df_soasia['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_namer= df[df[\"Region\"] == 'North America']\n",
    "print('North America INFORM: Hazard & Exposure risk score average: ', df_namer['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('North America INFORM: Vulnerability risk score average: ', df_namer['INFORM: Vulnerability risk score'].mean())\n",
    "print('North America INFORM: Lack of Coping Capacity risk score average: ', df_namer['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('North America INFORM risk score average: ', df_namer['INFORM: Epidemic risk score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create regional Hazard & Exposure risk column and map average region scores\n",
    "eur= df_eur['INFORM: Hazard & Exposure risk score'].mean()\n",
    "afr= df_afr['INFORM: Hazard & Exposure risk score'].mean()\n",
    "lat= df_lat['INFORM: Hazard & Exposure risk score'].mean()\n",
    "asia= df_asia['INFORM: Hazard & Exposure risk score'].mean()\n",
    "mena= df_mena['INFORM: Hazard & Exposure risk score'].mean()\n",
    "soasia= df_soasia['INFORM: Hazard & Exposure risk score'].mean()\n",
    "namer= df_namer['INFORM: Hazard & Exposure risk score'].mean()\n",
    "\n",
    "hazard_reg = {'Europe & Central Asia': eur, 'Sub-Saharan Africa': afr, 'Latin America & Caribbean': lat, 'East Asia & Pacific': asia, 'Middle East & North Africa': mena, 'South Asia': soasia, 'North America': namer}\n",
    "df['INFORM: Region Hazard & Exposure risk score'] = df['Region'].map(hazard_reg)\n",
    "\n",
    "#create regional Vulnerability risk column and map average region scores\n",
    "eur= df_eur['INFORM: Vulnerability risk score'].mean()\n",
    "afr= df_afr['INFORM: Vulnerability risk score'].mean()\n",
    "lat= df_lat['INFORM: Vulnerability risk score'].mean()\n",
    "asia= df_asia['INFORM: Vulnerability risk score'].mean()\n",
    "mena= df_mena['INFORM: Vulnerability risk score'].mean()\n",
    "soasia= df_soasia['INFORM: Vulnerability risk score'].mean()\n",
    "namer= df_namer['INFORM: Vulnerability risk score'].mean()\n",
    "\n",
    "vulnerability_reg = {'Europe & Central Asia': eur, 'Sub-Saharan Africa': afr, 'Latin America & Caribbean': lat, 'East Asia & Pacific': asia, 'Middle East & North Africa': mena, 'South Asia': soasia, 'North America': namer}\n",
    "df['INFORM: Region Vulnerability risk score'] = df['Region'].map(vulnerability_reg)\n",
    "\n",
    "#create regional Lack of Coping Capacity risk column and map average region scores\n",
    "eur= df_eur['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "afr= df_afr['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "lat= df_lat['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "asia= df_asia['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "mena= df_mena['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "soasia= df_soasia['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "namer= df_namer['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "\n",
    "coping_reg = {'Europe & Central Asia': eur, 'Sub-Saharan Africa': afr, 'Latin America & Caribbean': lat, 'East Asia & Pacific': asia, 'Middle East & North Africa': mena, 'South Asia': soasia, 'North America': namer}\n",
    "df['INFORM: Region Lack of Coping Capacity risk score'] = df['Region'].map(coping_reg)\n",
    "\n",
    "#create regional INFORM: Epidemic risk column and map average region scores\n",
    "eur= df_eur['INFORM: Epidemic risk score'].mean()\n",
    "afr= df_afr['INFORM: Epidemic risk score'].mean()\n",
    "lat= df_lat['INFORM: Epidemic risk score'].mean()\n",
    "asia= df_asia['INFORM: Epidemic risk score'].mean()\n",
    "mena= df_mena['INFORM: Epidemic risk score'].mean()\n",
    "soasia= df_soasia['INFORM: Epidemic risk score'].mean()\n",
    "namer= df_namer['INFORM: Epidemic risk score'].mean()\n",
    "\n",
    "epidemic_reg = {'Europe & Central Asia': eur, 'Sub-Saharan Africa': afr, 'Latin America & Caribbean': lat, 'East Asia & Pacific': asia, 'Middle East & North Africa': mena, 'South Asia': soasia, 'North America': namer}\n",
    "df['INFORM: Region Epidemic risk score'] = df['Region'].map(epidemic_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Income Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataframe for each income group and calculate average INFORM risk scores by income group\n",
    "df_upper= df[df[\"Income Group\"] == 'Upper middle income']\n",
    "print('Upper middle income INFORM: Hazard & Exposure risk score average: ', df_upper['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('Upper middle income INFORM: Vulnerability risk score average: ', df_upper['INFORM: Vulnerability risk score'].mean())\n",
    "print('Upper middle income INFORM: Lack of Coping Capacity risk score average: ', df_upper['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('Upper middle income INFORM risk score average: ', df_upper['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_lower= df[df[\"Income Group\"] == 'Lower middle income']\n",
    "print('Lower middle income INFORM: Hazard & Exposure risk score average: ', df_lower['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('Lower middle income INFORM: Vulnerability risk score average: ', df_lower['INFORM: Vulnerability risk score'].mean())\n",
    "print('Lower middle income INFORM: Lack of Coping Capacity risk score average: ', df_lower['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('Lower middle income INFORM risk score average: ', df_lower['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_low= df[df[\"Income Group\"] == 'Low income']\n",
    "print('Low income INFORM: Hazard & Exposure risk score average: ', df_low['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('Low income INFORM: Vulnerability risk score average: ', df_low['INFORM: Vulnerability risk score'].mean())\n",
    "print('Low income INFORM: Lack of Coping Capacity risk score average: ', df_low['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('Low income INFORM risk score average: ', df_low['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_oecd= df[df[\"Income Group\"] == 'High income: OECD']\n",
    "print('High income OECD INFORM: Hazard & Exposure risk score average: ', df_oecd['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('High income OECD INFORM: Vulnerability risk score average: ', df_oecd['INFORM: Vulnerability risk score'].mean())\n",
    "print('High income OECD INFORM: Lack of Coping Capacity risk score average: ', df_oecd['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('High income OECD INFORM risk score average: ', df_oecd['INFORM: Epidemic risk score'].mean())\n",
    "print()\n",
    "df_non_oecd= df[df[\"Income Group\"] == 'High income: nonOECD']\n",
    "print('High income nonOECD INFORM Hazard & Exposure risk score average: ', df_non_oecd['INFORM: Hazard & Exposure risk score'].mean())\n",
    "print('High income nonOECD INFORM Vulnerability risk score average: ', df_non_oecd['INFORM: Vulnerability risk score'].mean())\n",
    "print('High income nonOECD INFORM Lack of Coping Capacity risk score average: ', df_non_oecd['INFORM: Lack of Coping Capacity risk score'].mean())\n",
    "print('High income nonOECD INFORM risk score average: ', df_non_oecd['INFORM: Epidemic risk score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create regional Hazard & Exposure risk column and map average region scores\n",
    "upper= df_upper['INFORM: Hazard & Exposure risk score'].mean()\n",
    "lower= df_lower['INFORM: Hazard & Exposure risk score'].mean()\n",
    "low= df_low['INFORM: Hazard & Exposure risk score'].mean()\n",
    "oecd= df_oecd['INFORM: Hazard & Exposure risk score'].mean()\n",
    "non_oecd= df_non_oecd['INFORM: Hazard & Exposure risk score'].mean()\n",
    "\n",
    "hazard_inc = {'Upper middle income': upper, 'Lower middle income': lower, 'Low income': low, 'High income: OECD': oecd, 'High income nonOECD': non_oecd}\n",
    "df['INFORM: Income Group Hazard & Exposure risk score'] = df['Income Group'].map(hazard_inc)\n",
    "\n",
    "#create regional Vulnerability risk column and map average regon scores\n",
    "upper= df_upper['INFORM: Vulnerability risk score'].mean()\n",
    "lower= df_lower['INFORM: Vulnerability risk score'].mean()\n",
    "low= df_low['INFORM: Vulnerability risk score'].mean()\n",
    "oecd= df_oecd['INFORM: Vulnerability risk score'].mean()\n",
    "non_oecd= df_non_oecd['INFORM: Vulnerability risk score'].mean()\n",
    "\n",
    "vulnerability_inc = {'Upper middle income': upper, 'Lower middle income': lower, 'Low income': low, 'High income: OECD': oecd, 'High income nonOECD': non_oecd}\n",
    "df['INFORM: Income Group Vulnerability risk score'] = df['Income Group'].map(vulnerability_inc)\n",
    "\n",
    "#create regional Lack of Coping Capacity risk column and map average regon scores\n",
    "upper= df_upper['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "lower= df_lower['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "low= df_low['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "oecd= df_oecd['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "non_oecd= df_non_oecd['INFORM: Lack of Coping Capacity risk score'].mean()\n",
    "\n",
    "coping_inc = {'Upper middle income': upper, 'Lower middle income': lower, 'Low income': low, 'High income: OECD': oecd, 'High income nonOECD': non_oecd}\n",
    "df['INFORM: Income Group Lack of Coping Capacity risk score'] = df['Income Group'].map(coping_inc)\n",
    "\n",
    "#create regional INFORM: Epidemic risk column and map average regon scores\n",
    "upper= df_upper['INFORM: Epidemic risk score'].mean()\n",
    "lower= df_lower['INFORM: Epidemic risk score'].mean()\n",
    "low= df_low['INFORM: Epidemic risk score'].mean()\n",
    "oecd= df_oecd['INFORM: Epidemic risk score'].mean()\n",
    "non_oecd= df_non_oecd['INFORM: Epidemic risk score'].mean()\n",
    "\n",
    "epidemic_inc = {'Upper middle income': upper, 'Lower middle income': lower, 'Low income': low, 'High income: OECD': oecd, 'High income nonOECD': non_oecd}\n",
    "df['INFORM: Income Group Epidemic risk score'] = df['Income Group'].map(epidemic_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to classify sub-category risk score based on INFORM risk class values\n",
    "def risk(x):\n",
    "    if x >=6.5:\n",
    "        return 'Very High'\n",
    "    elif x >= 5:\n",
    "        return 'High'\n",
    "    elif x >= 3.5:\n",
    "        return 'Medium'\n",
    "    elif x >= 2:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'Very Low'\n",
    "\n",
    "#map INFORM: Hazard & Exposure risk scores to INFORM: Hazard & Exposure risk class column\n",
    "df['INFORM: Hazard & Exposure risk class'] = df['INFORM: Hazard & Exposure risk score'].map(lambda x: risk (x))\n",
    "\n",
    "#map INFORM: Vulnerability risk scores to INFORM: Hazard & Exposure risk class column\n",
    "df['INFORM: Vulnerability risk class'] = df['INFORM: Vulnerability risk score'].map(lambda x: risk (x))\n",
    "\n",
    "#map INFORM: Lack of Coping Capacity risk scores to INFORM: Hazard & Exposure risk class column\n",
    "df['INFORM: Lack of Coping Capacity risk class'] = df['INFORM: Lack of Coping Capacity risk score'].map(lambda x: risk (x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./datasets/all indicators_final_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
